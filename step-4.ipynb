{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thefuzz[levenshtein] in c:\\users\\63141\\appdata\\local\\anaconda3\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in c:\\users\\63141\\appdata\\local\\anaconda3\\lib\\site-packages (from thefuzz[levenshtein]) (3.9.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: thefuzz 0.22.1 does not provide the extra 'levenshtein'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "!pip install thefuzz[levenshtein]\n",
    "\n",
    "import thefuzz\n",
    "\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ipm = \"C:\\\\Users\\\\63141\\\\Desktop\\\\github_files_v2\\\\unmatched_ipm_R2.xlsx\"\n",
    "ipm = pd.read_excel(path_ipm)\n",
    "\n",
    "path_eia = \"C:\\\\Users\\\\63141\\\\Desktop\\\\github_files_v2\\\\unmatched_eia_R2.xlsx\"\n",
    "eia = pd.read_excel(path_eia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\63141\\AppData\\Local\\Temp\\ipykernel_7848\\2246793782.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  eia = eia.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
      "C:\\Users\\63141\\AppData\\Local\\Temp\\ipykernel_7848\\2246793782.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  ipm = ipm.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Turning all letters in the data frame to lowercase so they can match easier \n",
    "eia = eia.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "ipm = ipm.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy match with pre processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to convert Roman numerals I through X to integers\n",
    "def roman_to_int(roman):\n",
    "    roman_numerals = {\n",
    "        'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5,\n",
    "        'VI': 6, 'VII': 7, 'VIII': 8, 'IX': 9, 'X': 10,\n",
    "        'i': 1, 'ii': 2, 'iii': 3, 'iv': 4, 'v': 5,\n",
    "        'vi': 6, 'vii': 7, 'viii': 8, 'ix': 9, 'x': 10\n",
    "    }\n",
    "    return roman_numerals.get(roman, roman)\n",
    "\n",
    "# Function to replace Roman numerals with integers in plant names\n",
    "def replace_roman_numerals(name):\n",
    "    roman_pattern = r'\\b(I|II|III|IV|V|VI|VII|VIII|IX|X|i|ii|iii|iv|v|vi|vii|viii|ix|x)\\b'\n",
    "    matches = re.findall(roman_pattern, name)\n",
    "    for match in matches:\n",
    "        name = name.replace(match, str(roman_to_int(match)))\n",
    "    return name\n",
    "\n",
    "# Function to preprocess plant names\n",
    "def preprocess_name(name):\n",
    "    # Normalize to lower case\n",
    "    name = name.lower()\n",
    "    # Replace Roman numerals with integers\n",
    "    name = replace_roman_numerals(name)\n",
    "    # Remove special characters and common terms (e.g., 'wind', 'farm', etc.)\n",
    "    name = name.replace('wind', '').replace('farm', '').replace('project', '').replace('energy', '').replace('solar','').replace('llc','').replace('center','').replace('no','').replace('hydro','').replace('station','').replace('generating','').replace('dam','').replace('power','').replace(\n",
    "        'renewable','').replace('facility','').replace('plant','').replace('power','').replace('electric','')\n",
    "    name = ''.join(e for e in name if e.isalnum() or e.isspace())\n",
    "    return name.strip()\n",
    "\n",
    "# Fuzzy matching and merge function\n",
    "def fuzzy_merge(df1, df2, key1, key2, state_key, technology_key, threshold=85, limit=1):\n",
    "    \"\"\"\n",
    "    Perform fuzzy matching and merge between two DataFrames based on plant names,\n",
    "    but only if the state and technology type match. Each plant name can only match once.\n",
    "\n",
    "    df1, df2: DataFrames to merge\n",
    "    key1, key2: Column names for plant names to merge on\n",
    "    state_key: Column name for states to match\n",
    "    technology_key: Column name for technology to match\n",
    "    threshold: Minimum similarity score to consider a match\n",
    "    limit: Number of matches to return (best match)\n",
    "    \"\"\"\n",
    "    matched_names = set()\n",
    "    used_names = set()  # To keep track of names already used in matches\n",
    "\n",
    "    # Preprocess plant names in both DataFrames\n",
    "    df1['Cleaned Name'] = df1[key1].apply(preprocess_name)\n",
    "    df2['Cleaned Name'] = df2[key2].apply(preprocess_name)\n",
    "\n",
    "    def match_row(row):\n",
    "        # Filter df2 based on matching state and technology type\n",
    "        filtered_df2 = df2[\n",
    "            (df2[state_key] == row[state_key]) &\n",
    "            (df2[technology_key] == row[technology_key])\n",
    "        ]\n",
    "\n",
    "        # Apply fuzzy matching on the filtered DataFrame\n",
    "        if not filtered_df2.empty and pd.notnull(row['Cleaned Name']):\n",
    "            s = filtered_df2['Cleaned Name'].tolist()\n",
    "            # Filter out names already used in previous matches\n",
    "            s = [name for name in s if name not in used_names]\n",
    "            if not s:\n",
    "                return pd.Series([None, None], index=['best_match', 'match_score'])\n",
    "\n",
    "            best_match = process.extractOne(row['Cleaned Name'], s, scorer=fuzz.token_set_ratio)\n",
    "            if best_match and best_match[1] >= threshold:\n",
    "                best_match_name = best_match[0]\n",
    "                used_names.add(best_match_name)  # Mark this name as used\n",
    "                return pd.Series([best_match_name, best_match[1]], index=['best_match', 'match_score'])\n",
    "\n",
    "        return pd.Series([None, None], index=['best_match', 'match_score'])\n",
    "\n",
    "    # Apply matching function\n",
    "    match_results = df1.apply(match_row, axis=1)\n",
    "\n",
    "    # Rename columns to avoid overlap\n",
    "    match_results.columns = ['match_best_match', 'match_match_score']\n",
    "\n",
    "    # Append match results to df1\n",
    "    df1 = df1.join(match_results)\n",
    "\n",
    "    # Perform the merge based on the best matches found\n",
    "    merged_df = pd.merge(df1, df2, left_on='match_best_match', right_on='Cleaned Name', how='left', suffixes=('', '_df2'))\n",
    "\n",
    "    # Drop the 'match_best_match' column if it exists\n",
    "    if 'match_best_match' in merged_df.columns:\n",
    "        merged_df = merged_df.drop(columns=['match_best_match'])\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Example usage with your DataFrames:\n",
    "merged_ipm_eia = fuzzy_merge(eia, ipm, \n",
    "                              'Plant Name', 'Plant Name', \n",
    "                              'State', 'Merged Capacity Types', \n",
    "                              threshold=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_90 = merged_ipm_eia[merged_ipm_eia['match_match_score'] >= 90]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"C:\\\\Users\\\\63141\\\\Desktop\\\\github_files_v2\\\\GMR3.xlsx\"\n",
    "MS_90.to_excel(path1, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = ipm[~ipm['key'].isin(MS_90['key_df2'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\63141\\\\Desktop\\\\github_files_v2\\\\final_df.xlsx\"\n",
    "final_df.to_excel(path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
